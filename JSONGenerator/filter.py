import argparse
import collections
import logging
import re

import common


def fix_tmp_dir_outputs(filtered_output, working_dirs):
    pattern = re.compile("/tmp/nxf\.[0-9A-Za-z]{10}")
    fixed_output_dirs = {}

    for hash_id, v in working_dirs.items():
        outputs_for_task = filtered_output[hash_id]
        fixed_output_dirs_for_task = {}
        workdir = v['workdir']

        for path, size in outputs_for_task.items():
            old = path
            path = pattern.sub(workdir, path)
            logging.debug("%s -> %s", old, path)
            fixed_output_dirs_for_task[path] = size

        fixed_output_dirs[hash_id] = fixed_output_dirs_for_task

    return fixed_output_dirs


def filter_input_files(args):
    working_dirs = common.load_working_dirs(args.workdirfile)

    if args.io_file is not None:
        input_files, output_files = common.load_input_output_file(args.io_file)
    else:
        input_files, output_files = common.generate_input_output_file(working_dirs)

    number_of_tasks = len(working_dirs)
    logging.info(
        "Filtering Inputs/Outputs of %d Tasks based on strace reports", number_of_tasks)

    i = 0

    for hash_id, v in working_dirs.items():
        if i % 10 == 0:
            logging.info("Progress: %d%%", int((i / number_of_tasks) * 100))

        i += 1
        inputs_for_task = input_files[hash_id]
        outputs_for_task = output_files[hash_id]
        distinct_reads = set()
        distinct_write = set()
        # F-Up on my side, sometimes the folder is called workdir sometimes work
        for pid, strace in common.load_strace_files_from_working_dir(v['workdir'], work_dir_location=args.workdir):
            matches_reads = re.findall(
                r"\d{2}:\d{2}:\d{2}.\d{6} read\(\d<(.*)>,.* \d*\) = \d* <\d*\.\d*>", strace)
            matches_write = re.findall(
                r"\d{2}:\d{2}:\d{2}.\d{6} write\(\d<(.*)>,.* \d*\) = \d* <\d*\.\d*>", strace)

            matches_reads = list(
                filter(lambda t: t in inputs_for_task.keys(), matches_reads))
            matches_write = list(
                filter(lambda t: t in outputs_for_task.keys(), matches_write))

            for strace_filename in matches_reads:
                distinct_reads.add(strace_filename)
            for strace_filename in matches_write:
                distinct_write.add(strace_filename)
        n_unfiltered_inputs, n_unfiltered_outputs = len(
            inputs_for_task), len(outputs_for_task)

        for k in set(inputs_for_task) - distinct_reads:
            del inputs_for_task[k]

        for k in set(outputs_for_task) - distinct_write:
            del outputs_for_task[k]

        logging.info("Inputs: %d -> %d | Outputs: %d -> %d",
                     n_unfiltered_inputs,
                     len(inputs_for_task),
                     n_unfiltered_outputs,
                     len(outputs_for_task))

    return input_files, fix_tmp_dir_outputs(output_files, working_dirs)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='Exclude unused files from the IOFile generated by Nextflow using the strace output')
    parser.add_argument('workdirfile', type=str,
                        help='path to the workdirs file with the format <hash> <workdir> <name>. Can be generated using nextflow log')
    parser.add_argument('--io-file', dest='io_file', type=str, default=None,
                        help='path to the UNFILTERED strace io file, will be generated from the workdir file if ommitted')
    parser.add_argument('--work-dir', dest='workdir', default='../work', type=str,
                        help='path to the working directory on the local machine')
    parser.add_argument('--output', dest='output', default='filtered.txt', type=str,
                        help='path to the output file')
    parser.add_argument('-v', dest='logging', default='INFO', type=str,
                        help='logging level')

    args = parser.parse_args()

    logging.basicConfig()
    logging.root.setLevel(args.logging)
    filterd_input, filtered_output = filter_input_files(args)
    common.write_in_out_file(filterd_input, filtered_output, args.output)
